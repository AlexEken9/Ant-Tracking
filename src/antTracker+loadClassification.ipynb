{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_PATH = \"\" # Complete path of the video you want to proccess\n",
    "DETECTION_MODEL_PATH = \"\" # Complete path of the file \"antDetection.pt\"\n",
    "CLASSIFICATION_MODEL_PATH = \"\" # Complete path of the file \"loadClassification.pt\"\n",
    "\n",
    "output_filename = \"filename.mp4\"  # Set the output video filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "BBOX_PADDING = 15 # This value is how much (in pixels) you want to look around the bounding box in each detection. This is used for load detection.\n",
    "LOAD_THRESHOLD = 0.95 # This value is how sure the model has to consider that the ant has load."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(SOURCE_PATH)\n",
    "detection_model = YOLO(DETECTION_MODEL_PATH)\n",
    "classification_model = YOLO(CLASSIFICATION_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the video writer parameters\n",
    "output_width, output_height = cap.get(3), cap.get(4)\n",
    "fps = 30  # Adjust the frames per second (fps) as needed\n",
    "\n",
    "# Define the video writer object\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "video_writer = cv2.VideoWriter(output_filename, fourcc, fps, (int(output_width), int(output_height)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumberOfFrames(video):\n",
    "    numberOfFrames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    return numberOfFrames\n",
    "\n",
    "\n",
    "numberOfFrames = getNumberOfFrames(cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns the new bbox after adding the BBOX_PADDING\n",
    "def extract_object(frame, bbox, padding):\n",
    "    x, y, x2, y2 = bbox\n",
    "    padded_x = max(0, x - padding)\n",
    "    padded_y = max(0, y - padding)\n",
    "    padded_x2 = min(frame.shape[1], x2 + padding)\n",
    "    padded_y2 = min(frame.shape[0], y2 + padding)\n",
    "    object_frame = frame[padded_y:padded_y2, padded_x:padded_x2]\n",
    "    return object_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function runs the inference on the classification model to determine if an ant is loaded or not and returns the confidence of the ant in the frame being loaded.\n",
    "def getLoadProb(frame):\n",
    "    results = classification_model(frame, verbose=False)\n",
    "\n",
    "    for r in results:\n",
    "        load_prob = np.array(r.probs.data.cpu())[0]\n",
    "\n",
    "    return load_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function adds the ant id and its probability of being loaded into the dictionary that stores all the probabilities of each ant.\n",
    "def addLoadProb(antID, prob, dictionary):\n",
    "    if antID in dictionary:\n",
    "        dictionary[antID].append(prob)\n",
    "    else:   \n",
    "        dictionary[antID] = [prob]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function checks how many times the load probability of an ant surpassed the threshold and returns it\n",
    "def calcLoadProb(probsArray):\n",
    "    loadProb = np.sum(np.array(probsArray) > LOAD_THRESHOLD)\n",
    "    return loadProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paints a rectangle with rounded corners. This is just for aesthetics.\n",
    "def rounded_rectangle(img, start, end, color, thickness, r):\n",
    "    x1, y1 = start\n",
    "    x2, y2 = end\n",
    "    cv2.line(img, (x1 + r, y1), (x2 - r, y1), color, thickness)\n",
    "    cv2.line(img, (x1, y1 + r), (x1, y2 - r), color, thickness)\n",
    "    cv2.line(img, (x1 + r, y2), (x2 - r, y2), color, thickness)\n",
    "    cv2.line(img, (x2, y1 + r), (x2, y2 - r), color, thickness)\n",
    "    cv2.ellipse(img, (x1 + r, y1 + r), (r, r), 180, 0, 90, color, thickness)\n",
    "    cv2.ellipse(img, (x2 - r, y1 + r), (r, r), 270, 0, 90, color, thickness)\n",
    "    cv2.ellipse(img, (x1 + r, y2 - r), (r, r), 90, 0, 90, color, thickness)\n",
    "    cv2.ellipse(img, (x2 - r, y2 - r), (r, r), 0, 0, 90, color, thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Frames: 907/908\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING  'source' is missing. Using 'source=D:\\TFG\\tfg\\Lib\\site-packages\\ultralytics\\assets'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Frames: 908/908\r"
     ]
    }
   ],
   "source": [
    "ant_paths = {} # This dictionary stores the path traveled of each ant\n",
    "ant_loadProbs = {} #DICTIONARY ANT_ID: ARRAY LOAD PROBABILITY\n",
    "\n",
    "# Main loop\n",
    "ret = True\n",
    "processedFrames = 0\n",
    "while ret:\n",
    "    print(\"Processed Frames: \" + str(processedFrames) + \"/\" + str(numberOfFrames), end=\"\\r\")\n",
    "    ret, frame = cap.read()\n",
    "    try:\n",
    "        results = detection_model.track(frame, persist=True, verbose=False)\n",
    "        result = results[0]\n",
    "    except:\n",
    "        break\n",
    "\n",
    "    if result.boxes.id is None:\n",
    "        break\n",
    "    \n",
    "    paintedFrame = frame.copy()\n",
    "    bboxes = np.array(result.boxes.xyxy.cpu(), dtype=\"int\")\n",
    "    ids = np.array(result.boxes.id.cpu(), dtype=\"int\")\n",
    "\n",
    "    for (bbox, id) in zip(bboxes, ids):\n",
    "        objectFrame = extract_object(frame, bbox, BBOX_PADDING)\n",
    "        x, y, x2, y2 = bbox\n",
    "        addLoadProb(str(id), getLoadProb(objectFrame), ant_loadProbs)\n",
    "        antLoadProb = calcLoadProb(ant_loadProbs[str(id)])\n",
    "\n",
    "\n",
    "        center = (int((x + x2) / 2), int((y + y2) / 2))\n",
    "        if id not in ant_paths:\n",
    "            ant_paths[id] = [center]\n",
    "        else:\n",
    "            ant_paths[id].append(center)\n",
    "\n",
    "        if len(ant_paths[id]) > 1:\n",
    "            for i in range(1, len(ant_paths[id])):\n",
    "                cv2.line(paintedFrame, ant_paths[id][i - 1], ant_paths[id][i], (30, 240, 240), 2)\n",
    "\n",
    "        if antLoadProb > 5:\n",
    "            rounded_rectangle(paintedFrame, (x, y), (x2, y2), (240, 240, 30), 3, 2)\n",
    "            cv2.putText(paintedFrame, \"Ant + Load \" + str(id), (x, y - 5), cv2.FONT_HERSHEY_PLAIN, 1, (240, 240, 30), 2)\n",
    "        else:\n",
    "            rounded_rectangle(paintedFrame, (x, y), (x2, y2), (255, 69, 0), 2, 2)\n",
    "            cv2.putText(paintedFrame, \"Ant \" + str(id), (x, y - 5), cv2.FONT_HERSHEY_PLAIN, 1, (255, 69, 0), 1)\n",
    "\n",
    "  \n",
    "    video_writer.write(paintedFrame)\n",
    "    processedFrames += 1\n",
    "\n",
    "video_writer.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
